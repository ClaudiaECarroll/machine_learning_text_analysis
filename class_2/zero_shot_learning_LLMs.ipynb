{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zero Shot Sentiment Analysis with Hugging Face Models"
      ],
      "metadata": {
        "id": "TBissH4a3y1l"
      },
      "id": "TBissH4a3y1l"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BZsLQ2faKpLL"
      },
      "id": "BZsLQ2faKpLL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm # a package for creating progress bars\n",
        "import math\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available() # this command will return True if a compatible GPU is available"
      ],
      "metadata": {
        "id": "S4We0raEuqUU"
      },
      "id": "S4We0raEuqUU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "beda8b6c",
      "metadata": {
        "id": "beda8b6c"
      },
      "source": [
        "## Zero-shot classification with RoBERTa\n",
        "\n",
        "</p> The RoBERTa model is a version of the BERT model that has been improved with additional training data and changes to the model architecture. The RoBERTa-large-mnli model is RoBERTa fine-tuned with the  Multi-Genre Natural Language Inference dataset (https://paperswithcode.com/dataset/multinli) to improve performance on classification tasks.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6412a264",
      "metadata": {
        "id": "6412a264"
      },
      "outputs": [],
      "source": [
        "# Loading a model from huggingface, specifying the zero-shot-classification pipeline from Hugging Face Transformers\n",
        "\n",
        "model_2 = pipeline(\"zero-shot-classification\", model=\"roberta-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82b4136",
      "metadata": {
        "id": "f82b4136"
      },
      "outputs": [],
      "source": [
        "#Providing an example text, and the labels we want to use for classification\n",
        "\n",
        "text = \"The service at the restaurant was amazing, but the food was just average.\"\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a8224c",
      "metadata": {
        "id": "b0a8224c"
      },
      "outputs": [],
      "source": [
        "# Applying the model to the example sentence\n",
        "\n",
        "result = model_2(text, labels)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bb7a1e",
      "metadata": {
        "id": "87bb7a1e"
      },
      "outputs": [],
      "source": [
        "# Trying a different classification task, with different labels\n",
        "\n",
        "labels2 = [\"food\", \"theatre\", \"movies\", \"books\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9378e69b",
      "metadata": {
        "id": "9378e69b"
      },
      "outputs": [],
      "source": [
        "# Applying the model to the example sentence with the new labels\n",
        "\n",
        "result = model_2(text, labels2)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aa656cb",
      "metadata": {
        "id": "7aa656cb"
      },
      "source": [
        "## Zero-shot classification with DistilBERT SST-2\n",
        "\n",
        "</p>Now, we will use a similar zero-shot method using a pre-trained model. However, this time we will use a model that has apready been fine-tuned specifically for sentiment analysis. This model(https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) is a DistilBERT model fine-tuned on the Stanford Sentiment Treebank (https://huggingface.co/datasets/stanfordnlp/sst2), a dataset of over 200,000 phrases labelled as positive or negative by human labellers. DistilBERT is a smaller version of the BERT LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc8b096",
      "metadata": {
        "id": "0fc8b096"
      },
      "outputs": [],
      "source": [
        "# Loading the model\n",
        "\n",
        "model_2 = pipeline(model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85acbb5d",
      "metadata": {
        "id": "85acbb5d"
      },
      "outputs": [],
      "source": [
        "# applying the model to an example sentence (note, we do not speciy labels here, as the model has sentiment labels built in)\n",
        "\n",
        "text_2 = \"I love using Transformers. It's so easy and powerful!\"\n",
        "\n",
        "result = model_2(text_2)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ed449f",
      "metadata": {
        "id": "96ed449f"
      },
      "source": [
        "## Testing a DistilBERT SST-2 on a pre-labelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e685b6",
      "metadata": {
        "id": "93e685b6"
      },
      "outputs": [],
      "source": [
        "# Load in the example dataset of IMDB movie reviews\n",
        "\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TRIADS_workshops/ml_text_analysis/IMDB_short_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ffcdba0",
      "metadata": {
        "id": "9ffcdba0"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787acde6",
      "metadata": {
        "id": "787acde6"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first review just to take a look!\n",
        "\n",
        "print(df_test[\"review\"][0])"
      ],
      "metadata": {
        "id": "fIYlTP8UsC6a"
      },
      "id": "fIYlTP8UsC6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdafd920",
      "metadata": {
        "id": "cdafd920"
      },
      "outputs": [],
      "source": [
        "# Creating empty lists to store our sentiment labels and scores\n",
        "\n",
        "sentiments = []\n",
        "scores = []\n",
        "\n",
        "# Looping through the dataframe and applying out model to each review, then saving the label and sentiment score to new columns\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    phrase = row[\"review\"]\n",
        "    output = model_3(phrase)\n",
        "    sentiment = output[0][\"label\"]\n",
        "    score = output[0][\"score\"]\n",
        "    sentiments.append(sentiment)\n",
        "    scores.append(score)\n",
        "\n",
        "\n",
        "df_test['model_sentiment'] = sentiments\n",
        "df_test['model_score'] = scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9345532",
      "metadata": {
        "id": "c9345532"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a38061d",
      "metadata": {
        "id": "4a38061d"
      },
      "outputs": [],
      "source": [
        "# Doing some basic math to calculate the accuracy rate compared to the human labels\n",
        "\n",
        "correct_predictions = 0\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    if row['sentiment'] == row['model_sentiment'].lower():\n",
        "        correct_predictions  += 1\n",
        "\n",
        "print(correct_predictions)\n",
        "\n",
        "\n",
        "accuracy = (correct_predictions * 100) / len(df_test)\n",
        "print(accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Machine Translation with Hugging Face Models\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DchWBEeLuxfH"
      },
      "id": "DchWBEeLuxfH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will switch from sentiment analysis to machine translation. Machine translation is a text-generation task, rather than a classification task, as it generates new text in the target language, that captures the meaning of the text in the first language.\n",
        "\n"
      ],
      "metadata": {
        "id": "KdG__9Ia5qvf"
      },
      "id": "KdG__9Ia5qvf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The first model we will try is the Opus machine translation model from the Helsinki-NLP lab. Here we will try their model fine-tuned for translating French to English, but they have several thousand models on their repository for different language pairs and translation domains."
      ],
      "metadata": {
        "id": "TBa1sEuH79aM"
      },
      "id": "TBa1sEuH79aM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a sample dataset from GitHub and save it as a dataframe\n",
        "\n",
        "europarl = pd.read_csv('https://github.com/bestvater/misc/raw/master/europarl_en-fr_5000.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "jiMf3zkJuz-N"
      },
      "id": "jiMf3zkJuz-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shorten the dataset to make it quicker to work with!\n",
        "\n",
        "europarl = europarl.loc[0:99]\n",
        "\n",
        "europarl.head()"
      ],
      "metadata": {
        "id": "SYL7Ns1cL9Zc"
      },
      "id": "SYL7Ns1cL9Zc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load translation pipeline for French to English\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
      ],
      "metadata": {
        "id": "f9VI4pbjvEhb"
      },
      "id": "f9VI4pbjvEhb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate a French sentence\n",
        "result = translator(\"Je suis ravi de vous rencontrer.\")\n",
        "\n",
        "print(result)\n",
        ""
      ],
      "metadata": {
        "id": "u6TFHGC6vmfy"
      },
      "id": "u6TFHGC6vmfy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store machine translations, then apply the model to every french text in the dataset and save the machine translation to a new column\n",
        "# This might take a minute!\n",
        "\n",
        "english_translations = []\n",
        "\n",
        "for index, row in europarl.iterrows():\n",
        "    phrase = row[\"fr_text\"]\n",
        "    translation = translator(phrase)\n",
        "    english_translations.append(translation[0]['translation_text'])\n",
        "\n",
        "europarl['machine_translation'] = english_translations\n",
        "\n",
        "europarl.head()"
      ],
      "metadata": {
        "id": "CMJ1ba3GvvVc"
      },
      "id": "CMJ1ba3GvvVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare human translations to machine translations\n",
        "\n",
        "print(\"Human translated English Text:\")\n",
        "print(europarl[\"en_text\"][0])\n",
        "print(\"Machine translated English Text:\")\n",
        "print(europarl[\"machine_translation\"][0])"
      ],
      "metadata": {
        "id": "txA5YW8s2l-D"
      },
      "id": "txA5YW8s2l-D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will try the same translation task using the same French texts, using a different model. Here we will use the Many to Many machine translation model, developed at Facebook. Unlike the Opus models which have distinct models for each language pair, the M2M model is designed to translate between any pairing amongst 100 languaged."
      ],
      "metadata": {
        "id": "DVABSBCr5md4"
      },
      "id": "DVABSBCr5md4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new model, specifying the languages, since this is a multilingual model!\n",
        "\n",
        "translator2 = pipeline(\"translation\", model=\"facebook/m2m100_418M\", src_lang=\"fr\", tgt_lang=\"en\")"
      ],
      "metadata": {
        "id": "7faLc8tK5lkf"
      },
      "id": "7faLc8tK5lkf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the new model to the French texts, and save the new translations to the dataframe\n",
        "# Again, might take a minute!\n",
        "\n",
        "english_translations_2 = []\n",
        "\n",
        "for index, row in europarl.iterrows():\n",
        "    phrase = row[\"fr_text\"]\n",
        "    translation = translator2(phrase)\n",
        "    english_translations_2.append(translation[0]['translation_text'])\n",
        "\n",
        "europarl['machine_translation_2'] = english_translations_2\n",
        "\n",
        "europarl.head()"
      ],
      "metadata": {
        "id": "AxCOql0w53eC"
      },
      "id": "AxCOql0w53eC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the human translated English text, and compare it to our two machine translated texts\n",
        "\n",
        "print(\"Human translated English Text:\")\n",
        "print(europarl[\"en_text\"][1])\n",
        "print(\"Machine translated English Text 1:\")\n",
        "print(europarl[\"machine_translation\"][1])\n",
        "print(\"Machine translated English Text 2:\")\n",
        "print(europarl[\"machine_translation_2\"][1])"
      ],
      "metadata": {
        "id": "Q396EfAM8tD2"
      },
      "id": "Q396EfAM8tD2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "\n",
        "### See if you can find another machine translation model on huggingface.co, and apply it to the French texts in our sample dataset. You can translate it to any language you like!"
      ],
      "metadata": {
        "id": "wPdo4PZFNQZk"
      },
      "id": "wPdo4PZFNQZk"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25zzSQKKNP74"
      },
      "id": "25zzSQKKNP74",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}